---
title: "Developing a purchasing impacts app based on USEEIO impact intensities"
output: html_notebook
---

by [Martin Brown](mailto::Martin.Brown@state.or.us)

### Introduction

In this R Markdown workbook I'm going to develop a Shiny app that takes spending data, expressed in BEA/NAICS categories, and converts those data to estimated supply chain (Scope 3) environmental impacts, based on impact intensities found in the USEEIO model.

For the time being the only impact category reported on will be greenhouse gas emissions, because the EPA has recently published a [convenient set of impact intensities for greenhouse gases](https://cfpub.epa.gov/si/si_public_record_Report.cfm?dirEntryId=349324&Lab=CESER).  But I will try to structure it so that if other impact categories become doable in the future, they can be added easily.

### Tracks of work

To make the app, I'll have to combine several sets of data and tracks of work.

To output estimated supply chain emissions, based on dollars expended, I need to combine:

* emissions intensity data, from the EPA's publications.  This is easy to download but needs to be filtered and reformed before it's used in the app.
* global warming potential data.  I definitely want to give some options here.
* spending data, from Oregon or any other source, but in categories compatible with the EPA's emissions intensities

So in general, impact=spending in dollars x emissions intensity (tons emitted/dollar) x global warming potential (unitless).

But to make that happen in the app,

* the emissions intensity data needs to be in a filtered tidy data frame
* the spending data has to be uploaded and checked for compatibility (inside the app)
* a number of global warming potential profiles have to be available

### Set up

```{r}
# load packages I like to use
library(checkpoint)
library(tidyverse)
library(readxl)
library(kableExtra)

# use packages as of a certain reference date
checkpoint(snapshot_date = "2021-06-15")

# see what my working directory is
getwd()
```

### Emissions intensities

I've downloaded the EPA's ghg emissions intensities from the web.  I need to choose the sheet(s) most relevant to me, download the data, and tidy it.  Maybe along the way I'll print out some of the documentation sheets.

```{r}
# set EPA ghg filespec
epaGHGdataFileSpec <-
  "source_data/SupplyChainEmissionFactorsforUSIndustriesCommodities.xlsx"
# find out what sheets are there
epaGHGdataAvailableSheets <-
  excel_sheets(path=epaGHGdataFileSpec)
kable(
  as.data.frame(epaGHGdataAvailableSheets), 
  caption="available sheets"
)
```
Since my goal is to find the supply chain emissions of purchases, it seems right to use the Commodity based tables.  Which of the many commodity options should I choose?  

The year records are a bit confusing, but I think they refer to versions of the I/O tables.  All of the emissions intensities are in kg per 2018 dollars.  TO DO: FIND OUT WHAT THE DIFFERENT YEARS REPRESENT.

But: assuming I want the most recent, what I should import is:

* 2016_Summary_Commodity
* 2016_Detail_Commodity

```{r}
# import my sheets of interest
epaGHGdataSet1raw <-
  read_excel(
    path=epaGHGdataFileSpec,
    sheet="2016_Summary_Commodity"
  )
epaGHGdataSet2raw <-
  read_excel(
    path=epaGHGdataFileSpec,
    sheet="2016_Detail_Commodity"
  )
```

Looks like there is a data dictionary I might want to print out for the record.  These are the field names in the Excel tables.

```{r}
epaGHGdataDictionary <-
  read_excel(path=epaGHGdataFileSpec, sheet="Data Dictionary")
kable(epaGHGdataDictionary) %>% 
  kable_styling(bootstrap_options = "bordered")
```

I'm not going to need all those fields.  Let's select and rename fields.

```{r}
# select desired fields and rename them for brevity
epaGHGdataSet1 <-
  epaGHGdataSet1raw %>%
  select(
    `Commodity Code`,
    `Commodity Name`,
    `Substance`,
    `Unit`,
    `Supply Chain Emission Factors without Margins`
  ) %>%
  rename(
    beaCode=`Commodity Code`,
    beaName=`Commodity Name`,
    substance=Substance,
    unit=Unit,
    impFactor=`Supply Chain Emission Factors without Margins`
  )
epaGHGdataSet2 <-
  epaGHGdataSet2raw %>%
  select(
    `Commodity Code`,
    `Commodity Name`,
    `Substance`,
    `Unit`,
    `Supply Chain Emission Factors without Margins`
  ) %>% 
  rename(
    beaCode=`Commodity Code`,
    beaName=`Commodity Name`,
    substance=Substance,
    unit=Unit,
    impFactor=`Supply Chain Emission Factors without Margins`
  )
```

Now I know I would like to combine these two tables -- so that users can enter expenditures in either detail or summary levels of detail (and mix and match).  That will be most convenient if the beaCodes and beaNames do not overlap between the two tables.  Let's check.

```{r}
epaGHGbeaCodes1 <-
  epaGHGdataSet1 %>% select(beaCode) %>% distinct() 
epaGHGbeaCodes2 <-
  epaGHGdataSet2 %>% select(beaCode) %>% distinct()
inner_join(
  epaGHGbeaCodes2 ,
  epaGHGbeaCodes1 ,
  by="beaCode"
) %>% print()
```

whew, it looks like none overlap.  Let's try the commodity names.

```{r}
epaGHGbeaNames1 <-
  epaGHGdataSet1 %>% select(beaName) %>% distinct() 
epaGHGbeaNames2 <-
  epaGHGdataSet2 %>% select(beaName) %>% distinct()
inner_join(
  epaGHGbeaNames2 %>% mutate(level="detail"),
  epaGHGbeaNames1 %>% mutate(level="summary"),
  by="beaName"
) %>% print()
```


Looks like there is a little overlap in the names.  But not in the codes.  So if I use codes as the key variable then it won't matter.  
 I could also visually indicate the summary level textually -- all caps maybe?
 
Let's try combining the names and printing them out as a table.

```{r}
# make a combined epa commodity table
epaAllCommodityTable <-
  bind_rows(
    epaGHGdataSet1 %>%
      select(beaCode, beaName) %>%
      mutate(
        dtlLvl="summary",
        beaName=str_to_upper(beaName)
      ) %>%
      distinct(),
    epaGHGdataSet2 %>%
      select(beaCode, beaName) %>%
      mutate(dtlLvl="detail") %>%
      distinct()
  ) %>%
  arrange(beaCode, beaName)
kable(epaAllCommodityTable) %>%
  kable_styling(bootstrap_options = "responsive")
```
Well, what this tells me is that I can definitely add the two tables together.  But I need to preserve the beaCode and (probably for clarity) also preserve the dtlLvl and also mark off the summary level somehow (as with all caps).

All right let's make it.

```{r}
# make the combined impact intensities table
epaGHGimpactIntensities <-
  bind_rows(
    epaGHGdataSet1 %>%
      mutate(
        dtlLvl="summary",
        beaName=str_to_upper(beaName)
      ),
    epaGHGdataSet2 %>%
      mutate(
        dtlLvl="detail"
      )
  ) %>%
  arrange(beaCode, beaName, substance)
```

So object epaGHGimpactIntensities is what I'll use.

```{r}
# clean up workspace by deleting most objects
rm(
  list=
    setdiff(
      ls(),
      c("epaGHGimpactIntensities", "epaGHGdataDictionary")
  )
)
```

### importing the spending data.

In the app I need to import a user's file and then check that their data meets the acceptable categories.

So let's develop the acceptable list first.

```{r}
# make acceptable spending category data frame & save it as disk file
okSpendingCats <-
  epaGHGimpactIntensities %>%
  select(beaCode, beaName, dtlLvl) %>%
  distinct() %>%
  arrange(beaCode, beaName)
saveRDS(okSpendingCats, "intermediate_data/okSpendingCats.RData")
```

Now, in a somewhat non-reproducible step, I'm going to create an Excel template to allow people to enter spending data in an acceptable format.  It is available in the "source_data" folder as "users_spending_data_blank.xlsx".  This may be copied and altered by users and uploaded to the app.

Now I've got to take some spending data and see how it matches up.  More generally, I've got to figure out how to "validate" the incoming data... 

* is it in the right format? (e.g. codes as text, spending as integer)
* do all the codes have entries in the okSpendingCats?

Let's try it with two different data files.

* Rivin's Oregon spending data file produced in 2020 (from an obsolete version of this analysis)
* A fictional spending data file using the template produced above.

```{r}
# get Rivin's draft spending file, circa 2020
exampleSpendingData1 <-
  read_excel(
    path="../quick-purchasing-impacts/source_data/oregon_spending_2020_04_23.xlsx",
    sheet="martin5",
    skip=4,
    col_names = TRUE,
    col_types = c("text", "text", "text", "numeric")
  ) %>%
  rename(
    userCategory=`DEQ Category`,
    beaCode=`BAE  Code`,
    userSpending=`BEA cost`
  ) %>%
  select(beaCode, userSpending, userCategory) %>%
  filter(userSpending > 0) %>%
  mutate(
    # a manual edit based on a typo discovered below
    beaCode=ifelse(beaCode=="GSLGH", "5412OP", beaCode)
  ) %>%
  arrange(beaCode, desc(userSpending))

# print out rows of spending data
print(nrow(exampleSpendingData1))

# count how many rows join based on beaCode
semi_join(
  exampleSpendingData1,
  okSpendingCats,
  by="beaCode"
) %>% nrow() %>% print()

# print out rows that don't match
anti_join(
  exampleSpendingData1,
  okSpendingCats,
  by="beaCode"
) %>% 
kable() %>% kable_styling(bootstrap_options = "responsive")
```

Good news -- nearly everything matched up.  The examination above uncovered just one mismatch, which I found a reasonable substitute for.

Ok, let's try the template I created.

```{r}
# import spreadsheet with spending data
exampleSpendingData2 <-
  read_excel(
    path="source_data/users_spending_data_sample.xlsx",
    skip=11,
    col_names = TRUE
  ) %>%
  select(beaCode, userSpending, userCategory) %>%
  filter(userSpending > 0) %>%
  mutate(
    # use this space for manual edits
  ) %>%
  arrange(beaCode, desc(userSpending))

# print out rows of spending data
print(nrow(exampleSpendingData2))

# count how many rows join based on beaCode
semi_join(
  exampleSpendingData2,
  okSpendingCats,
  by="beaCode"
) %>% nrow() %>% print()

# print out rows that don't match
anti_join(
  exampleSpendingData1,
  okSpendingCats,
  by="beaCode"
) %>% 
kable() %>% kable_styling(bootstrap_options = "responsive")
```
Looks like that's the way to do it.

* load in the table
* reduce to those 3 standard fields
* check for semi_joins and anti_joins
* print out any anti_joins

At this moment I'm going to create the file for the shiny app to see if I can upload data in the form of the template.

...

Looks like I got that working.  I'm going to have to add a lot of features later, like

* additional validation
* an example file to download
* choice of using preset data from ORegon

but that can go later.


### global warming potentials

The EPA data gives masses per expended $ for 3 particular gasses, and CO2 equivalents for one umbrella category "other gasses".  This gives the option of choosing your own Global Warming potentials (e.g. IPCC AR4 20 year, etc.), but dealing with those other gases will be a pain.

* CO2 masses will always have a GWP of 1 (from defintion of GWP).
* CH4 masses will have a varying GWP I can get from tables of GWP's.
* N2O masses will have a varying GWP I can get from tables of GWP's.
* the other gases are already reported with an inherent GWP (from AR4 100 year).  If I want to correct this I need to figure out the relationship of "other gas" GWP's under AR4 100 to their GWP's under other views.

Let's read in some GWP's and do some filtering.

```{r}
# filespec of spreadsheet with GWP's from GaBi
GWPfilespec <- "source_data/gwp_factors_from_gabi.xlsx"

# get list of sheets in source file
listOfGWPsheets <- 
  excel_sheets(path=GWPfilespec)

# read each sheet and label the estimates from sheet name
for (i in 1:length(listOfGWPsheets)) {
  tempDF <- 
    read_excel(
      path=GWPfilespec,
      sheet=listOfGWPsheets[i],
      skip=22,
      col_names=c("compound", "junk1", "junk2", "gwp", "junk3"),
      col_types=c("text", "numeric", "text", "numeric", "numeric")
    ) %>%
    select(compound, gwp) %>%
    filter(gwp>0) %>%
    mutate(
      gwpVersion=listOfGWPsheets[i],
      substance=
        case_when(
          compound=="Carbon dioxide [Inorganic emissions to air]" ~
            "carbon dioxide",
          compound=="Methane (biotic) [Organic emissions to air (group VOC)]" ~ "methane",
          compound=="Nitrous oxide (laughing gas) [Inorganic emissions to air]" ~ "nitrous oxide",
          TRUE ~ "other GHGs"
        )
    )
  
  if (i==1) {
    gwpCollection <- tempDF[0,]
  }
  
  gwpCollection <- 
    bind_rows(gwpCollection, tempDF) 
}

# now lets summarize that GWP collection by gas group.
GWPtoUseAlmost <-
  gwpCollection %>%
  mutate(log10gwp=log10(gwp)) %>%
  group_by(gwpVersion, substance) %>%
  summarise(log10gwp=mean(log10gwp)) %>%
  ungroup() %>%
  mutate(gwp=10**log10gwp) %>%
  select(-log10gwp)
# for the "other GHGs" I can't use those values as calculated.
# I have to use a standard... for now let's say AR5 100.
# when I get the data I should update that to AR4 100.
standardValueForOtherGases <-
  GWPtoUseAlmost %>% 
  filter(gwpVersion=="IPCC AR4 100", substance=="other GHGs") %>%
  pull(gwp)

GWPtoUse <-
  GWPtoUseAlmost %>%
  mutate(
    gwp=ifelse(
      substance=="other GHGs", gwp/standardValueForOtherGases, gwp
    )
  )

kable(GWPtoUse)
```
So looking at that table, all the figures for major gasses are correct.  For the "other gases" its supposed to be a ratio vs. the value for AR4 100.  The AR4 20 value makes sense.  Not sure about the AR5 values -- because unfortunately they did not come from completely compatible data sets.  I will have to see how much the other gases contribute to the results.  

If they contribute a lot, I may need to go back into that table and try to make the AR5 selections more compatible with AR4.  Looks like there are more gases in the AR5, so I would try to use the AR4 subset, maybe with a flag field?

Let's save that table to the intermediate zone so it can be used in the app.

```{r}
saveRDS(GWPtoUse, file="intermediate_data/GWPtoUse.RData")
```

### Putting it together in a sample calculation

so now I've got some example spending, e.g.

```{r}
kable(head(exampleSpendingData2))
```

and some emissions intensity data, e.g.

```{r}
kable(head(epaGHGimpactIntensities))
```

and some GWP data, eg.

```{r}
kable(head(GWPtoUse))
```

and all I need to do is put them together in a way that can be filtered.

so, impact=spending x intensity x gwp.
now that I think about it, the intensity and gwp tables will never change, so I can just merge them.

```{r}
# combine the intentsity and GWP tables
impactIntensitiesWithGWPversions <-
  full_join(
    epaGHGimpactIntensities %>%
      mutate(
        impactCategory="GHG emissions",
        impactUnits="kg CO2e"
    ),
    GWPtoUse,
    by="substance"
  )
# save the result as a disk file
saveRDS(
  impactIntensitiesWithGWPversions,
  "intermediate_data/impactIntensitiesWithGWPversions.RData"
)
```

now let's merge with some spending data and filter.
this is the kind of merge that will need to be made in the app.
users will select gwp version and (eventually) impact category

```{r}
# 
testDF <-
  left_join(
    exampleSpendingData2,
    impactIntensitiesWithGWPversions,
    by="beaCode"
  ) %>%
  filter(
    impactCategory=="GHG emissions" & 
    gwpVersion %in% "IPCC AR4 100"
  ) %>%
  mutate(
    impact=userSpending*impFactor*gwp,
    actualSpending=ifelse(substance=="carbon dioxide", userSpending, 0)
  )
```

now let's sum impacts by beaName and by userCategory

```{r}
testDF2 <-
  testDF %>%
  group_by(impactCategory, impactUnits, beaName) %>%
  summarise(
    userSpending=sum(actualSpending),
    impact=sum(impact)
  )
kable(testDF2)
```
and

```{r}
testDF3 <-
  testDF %>%
  group_by(impactCategory, impactUnits, userCategory) %>%
  summarise(
    userSpending=sum(actualSpending),
    impact=sum(impact)
  )
kable(testDF3)
```
ok, i have previewed the processing!

next session I should

* preview some illustrations
* start putting this stuff in the app




